{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "876e5dcb2d154e7f9ea5f0aca61c318f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b885ba8603046fc913e763529ffe6cb",
              "IPY_MODEL_4ae2a4dcd4ad4e3bb4fa687287fef75f",
              "IPY_MODEL_1a1507f3178640c3ae2fb2ed86d13d92"
            ],
            "layout": "IPY_MODEL_3564fac9d73a454596bb8ba6d09b322c"
          }
        },
        "6b885ba8603046fc913e763529ffe6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75ee0b8635144abba3d5d72896e831c1",
            "placeholder": "​",
            "style": "IPY_MODEL_cae23f6bc57c4f05a2a66f21479d08d9",
            "value": "README.md: 100%"
          }
        },
        "4ae2a4dcd4ad4e3bb4fa687287fef75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4212ffa8867e45c5bc9e8a1e0eae2727",
            "max": 7940,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c43bcc23efd049898e977dc2b4babbc0",
            "value": 7940
          }
        },
        "1a1507f3178640c3ae2fb2ed86d13d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b0f57a0d54048c294d58103d5c1d5ff",
            "placeholder": "​",
            "style": "IPY_MODEL_d381e60ce6674b3697c9f60494d8a76a",
            "value": " 7.94k/7.94k [00:00&lt;00:00, 394kB/s]"
          }
        },
        "3564fac9d73a454596bb8ba6d09b322c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75ee0b8635144abba3d5d72896e831c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cae23f6bc57c4f05a2a66f21479d08d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4212ffa8867e45c5bc9e8a1e0eae2727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43bcc23efd049898e977dc2b4babbc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b0f57a0d54048c294d58103d5c1d5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d381e60ce6674b3697c9f60494d8a76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3343ae1ee10c4a65b0153c236dc6428a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f20af389cdc48f1905bff84c62efee6",
              "IPY_MODEL_337098b9b45c46f6929fa4c8c8197a84",
              "IPY_MODEL_15332170c70e4f7c888d6bbe2f64ef78"
            ],
            "layout": "IPY_MODEL_6d6d252f9ef1423392498e5adc4c134d"
          }
        },
        "8f20af389cdc48f1905bff84c62efee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593cdd3871b0460db8a0f365c0791ba5",
            "placeholder": "​",
            "style": "IPY_MODEL_1811f55e1c1c4db6af73790b6b24c8a9",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "337098b9b45c46f6929fa4c8c8197a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_761aff5619984cfbbd51c169e28e3e09",
            "max": 2306545,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_303e7c747d3e47139665045fe2867bb8",
            "value": 2306545
          }
        },
        "15332170c70e4f7c888d6bbe2f64ef78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eab52850f004dedb47488a90a9f1e35",
            "placeholder": "​",
            "style": "IPY_MODEL_b65b404f54384587935e46ba3f73e02d",
            "value": " 2.31M/2.31M [00:00&lt;00:00, 24.5MB/s]"
          }
        },
        "6d6d252f9ef1423392498e5adc4c134d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "593cdd3871b0460db8a0f365c0791ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1811f55e1c1c4db6af73790b6b24c8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "761aff5619984cfbbd51c169e28e3e09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "303e7c747d3e47139665045fe2867bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6eab52850f004dedb47488a90a9f1e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b65b404f54384587935e46ba3f73e02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b1c4dc336654b7abc4a6936875a8ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b159ee92e324ffba8c2ae882e4f7075",
              "IPY_MODEL_bdc85e3fb81346afa7eade27d980ec94",
              "IPY_MODEL_228c25c6d34a40a3888d6dee0d3f6d87"
            ],
            "layout": "IPY_MODEL_015b8fc4c6bf4309a997628d03b09904"
          }
        },
        "7b159ee92e324ffba8c2ae882e4f7075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a72e7fdc60a74c80a0d79858a98ebf19",
            "placeholder": "​",
            "style": "IPY_MODEL_dcfe543a35714b58957b3d3145fd5a0e",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "bdc85e3fb81346afa7eade27d980ec94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87406ddc5af4a2b88a2cae590376362",
            "max": 419088,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41b8a395b6d542e4a761a690608d037c",
            "value": 419088
          }
        },
        "228c25c6d34a40a3888d6dee0d3f6d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d75bb5f2a73947099321b875c14cd452",
            "placeholder": "​",
            "style": "IPY_MODEL_617787300048487a92c9a75dcbeb328d",
            "value": " 419k/419k [00:00&lt;00:00, 20.8MB/s]"
          }
        },
        "015b8fc4c6bf4309a997628d03b09904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a72e7fdc60a74c80a0d79858a98ebf19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcfe543a35714b58957b3d3145fd5a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c87406ddc5af4a2b88a2cae590376362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41b8a395b6d542e4a761a690608d037c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d75bb5f2a73947099321b875c14cd452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "617787300048487a92c9a75dcbeb328d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a6d95e682ef48d6a7231dfcbb079b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e04d362d95e3499ea28152c537e6e5a7",
              "IPY_MODEL_96e57470d1db43adbf17cd9a44d71151",
              "IPY_MODEL_39e8a53906724dcda1d5e2b07394d0ad"
            ],
            "layout": "IPY_MODEL_805066eebe5142ed8abcc514b922df66"
          }
        },
        "e04d362d95e3499ea28152c537e6e5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb85ffdccd4a49c69159921fdf258e6e",
            "placeholder": "​",
            "style": "IPY_MODEL_a98ecaa08a474d19ba6eed9f839e96a7",
            "value": "Generating train split: 100%"
          }
        },
        "96e57470d1db43adbf17cd9a44d71151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0b698d5364e42bda7351e00ed6a2cbe",
            "max": 7473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48c671c8822e4c57bc73d6ea0a6bd070",
            "value": 7473
          }
        },
        "39e8a53906724dcda1d5e2b07394d0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1763e0e18301478bb61e8ea5ef8ad05c",
            "placeholder": "​",
            "style": "IPY_MODEL_1623a50bf22c493580944cc645b1a7a1",
            "value": " 7473/7473 [00:00&lt;00:00, 74820.87 examples/s]"
          }
        },
        "805066eebe5142ed8abcc514b922df66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb85ffdccd4a49c69159921fdf258e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98ecaa08a474d19ba6eed9f839e96a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0b698d5364e42bda7351e00ed6a2cbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48c671c8822e4c57bc73d6ea0a6bd070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1763e0e18301478bb61e8ea5ef8ad05c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1623a50bf22c493580944cc645b1a7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56e96c400265447a935278adb1e1ae51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ceb8580fd6b43e4baccad792df1694e",
              "IPY_MODEL_40c490b668534a4bb570850c933df81f",
              "IPY_MODEL_9734c097136f4bc8b197170ddbcc1021"
            ],
            "layout": "IPY_MODEL_3e57986017834fd99e742ffe259f06d2"
          }
        },
        "4ceb8580fd6b43e4baccad792df1694e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4a35db3b4a44677a5c76c19570f9535",
            "placeholder": "​",
            "style": "IPY_MODEL_41bcb132d4ba48f5a5f05d50f22d121e",
            "value": "Generating test split: 100%"
          }
        },
        "40c490b668534a4bb570850c933df81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63b6e7eff5194e8aa6dfe0c773bbd97c",
            "max": 1319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad3e07c96b104910b8c8b95fc6d47ba6",
            "value": 1319
          }
        },
        "9734c097136f4bc8b197170ddbcc1021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_232b1ec4cae34ade8821cc557441d7f5",
            "placeholder": "​",
            "style": "IPY_MODEL_b7b64e0fa85c4d1f8117831a23dbb1e8",
            "value": " 1319/1319 [00:00&lt;00:00, 29056.89 examples/s]"
          }
        },
        "3e57986017834fd99e742ffe259f06d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a35db3b4a44677a5c76c19570f9535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bcb132d4ba48f5a5f05d50f22d121e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63b6e7eff5194e8aa6dfe0c773bbd97c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad3e07c96b104910b8c8b95fc6d47ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "232b1ec4cae34ade8821cc557441d7f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b64e0fa85c4d1f8117831a23dbb1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mixture Of Reasoning Experts (MoRE)"
      ],
      "metadata": {
        "id": "VLX3taA_-a_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bước 1: Như đã thực hiện trong hình\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CPhPBlL9-f6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Mixture of Reasoning Experts (MORE)**  \n",
        "Phần này giới thiệu khung làm việc **Mixture of Reasoning Experts (MORE)**, bao gồm cách xây dựng các chuyên gia suy luận đa dạng, cách kết hợp chúng, và cách dự đoán tính chính xác của câu trả lời.  \n",
        "\n",
        "**3.1 Các chuyên gia suy luận chuyên biệt**  \n",
        "Bước đầu tiên của hệ thống **MORE** là thu thập một tập hợp đa dạng các mô hình chuyên biệt để có thể kết hợp điểm mạnh của chúng thông qua chiến lược tổ hợp. Mặc dù có nhiều cách để xây dựng các mô hình QA chuyên biệt, chúng tôi thiết kế các chuyên gia suy luận chuyên biệt thông qua việc sử dụng lời nhắc (prompting) cho một mô hình ngôn ngữ lớn (LLM), vì chúng đạt độ chính xác hàng đầu trong nhiều tác vụ suy luận.  \n",
        "\n",
        "Chúng tôi chuyên biệt hóa mô hình **Codex** (Chen et al., 2021) cho các loại suy luận khác nhau bằng bốn phương pháp nhắc chuyên biệt (các lời nhắc mẫu được liệt kê trong Phụ lục, Hình 3):  \n",
        "\n",
        "- **Chuyên gia thực tế (Factual expert)** với lời nhắc được tăng cường bởi truy xuất thông tin. Theo Si và cộng sự (2023a), với mỗi câu hỏi, chúng tôi truy xuất 10 đoạn văn bản liên quan nhất từ Wikipedia bằng công cụ **Contriever** (Izacard et al., 2022) và thêm chúng vào lời nhắc ngay trước câu hỏi.  \n",
        "- **Chuyên gia suy luận đa bước (Multihop expert)** với lời nhắc theo phương pháp **Chain-of-Thought (CoT)** (Wei et al., 2022b). Chúng tôi thêm các lý giải được viết tay sau mỗi câu hỏi mẫu trong lời nhắc để gợi ra quy trình suy luận nhiều bước cho câu hỏi.  \n",
        "- **Chuyên gia toán học (Math expert)** cũng sử dụng lời nhắc CoT. Chúng tôi thêm các giải thích đi kèm được cung cấp trong **GSM8K** sau mỗi câu hỏi mẫu trong lời nhắc để gợi ra các bước suy luận tương tự cho câu hỏi.  \n",
        "- **Chuyên gia thường thức (Commonsense expert)** với lời nhắc kiến thức được tạo tự động (generated knowledge prompting) (Liu et al., 2021). Chúng tôi tạo ra 10 mẩu thông tin liên quan đến mỗi câu hỏi bằng mô hình **Codex** và thêm chúng vào lời nhắc ngay trước câu hỏi.  \n",
        "\n",
        "Sau khi thu thập dự đoán từ mỗi chuyên gia, chúng tôi huấn luyện một bộ phân loại để chọn ra câu trả lời tốt nhất. Điều này cho phép **MORE** kết hợp bốn mô hình chuyên biệt mà không cần biết trước kiểu suy luận của câu hỏi.  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "IMttkQze-4Fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bước 2: Chọn câu hỏi bằng random forest classifier\n",
        "\n"
      ],
      "metadata": {
        "id": "W9fOSUi5-86M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 Kết hợp thông qua lựa chọn câu trả lời**  \n",
        "Phương pháp **MORE** kết hợp điểm mạnh của các chuyên gia suy luận bằng cách sử dụng một bộ phân loại ngẫu nhiên rừng (random forest classifier) dựa trên đặc trưng để đánh giá mỗi câu trả lời. Điểm số này được dùng để chọn câu trả lời cuối cùng và xác định khi nào nên bỏ qua câu hỏi.\n",
        "\n",
        " **Bộ đặc trưng**  (feature set for model random forcast)\n",
        "- **Các đặc trưng thiết kế thủ công**:\n",
        "  - **Loại chuyên gia** (expert type).  \n",
        "  - **Đặc điểm câu hỏi**: từ khóa câu hỏi, độ dài, có chứa giá trị số hay không.  \n",
        "  - **Đặc điểm câu trả lời**: độ tự tin, độ dài, mức độ trùng khớp từ khóa với câu hỏi, ngữ cảnh, và lý giải.  \n",
        "  - **Đồng thuận giữa các chuyên gia**: tần suất câu trả lời được dự đoán giống nhau bởi các chuyên gia, mức độ trùng khớp từ khóa giữa các câu trả lời.  \n",
        "\n",
        " **Huấn luyện bộ phân loại**  \n",
        "- **Dữ liệu huấn luyện**: Giữ lại 100 mẫu từ mỗi bộ dữ liệu QA (tổng cộng 1200 mẫu) làm dữ liệu huấn luyện.  \n",
        "- **Mục tiêu**: Huấn luyện bộ phân loại để dự đoán xem câu trả lời của mô hình chuyên gia có chính xác hay không (nhị phân).  \n",
        "- Trong quá trình suy luận (inference), câu trả lời có điểm số cao nhất sẽ được chọn. Nếu điểm số thấp hơn ngưỡng, hệ thống sẽ bỏ qua không trả lời.  \n",
        "\n",
        " **Các thí nghiệm khác**  \n",
        "- Thử nghiệm với các bộ phân loại khác và tinh chỉnh các mô hình ngôn ngữ tiền huấn luyện như BERT, nhưng không hiệu quả bằng random forest.  \n",
        "\n"
      ],
      "metadata": {
        "id": "-MjIyIvR_Arf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "5TWRzl6JR4F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install instructor datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Buj6Q9BXR6OC",
        "outputId": "2465baa6-6fb8-4c27-fcf6-f23d83f04a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting instructor\n",
            "  Downloading instructor-1.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor) (3.11.2)\n",
            "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /usr/local/lib/python3.10/dist-packages (from instructor) (0.16)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from instructor) (3.1.4)\n",
            "Collecting jiter<0.7,>=0.6.1 (from instructor)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from instructor) (1.54.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from instructor) (2.9.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from instructor) (2.23.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.10/dist-packages (from instructor) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from instructor) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from instructor) (9.0.0)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor) (0.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor) (3.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->instructor) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->instructor) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->instructor) (0.27.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.52.0->instructor) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.8.0->instructor) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.32.3->instructor) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.32.3->instructor) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.32.3->instructor) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.32.3->instructor) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor) (2.18.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.9.0->instructor) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.9.0->instructor) (1.5.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.52.0->instructor) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->instructor) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->instructor) (0.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading instructor-1.7.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, jiter, fsspec, dill, multiprocess, instructor, datasets\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.7.1\n",
            "    Uninstalling jiter-0.7.1:\n",
            "      Successfully uninstalled jiter-0.7.1\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 instructor-1.7.0 jiter-0.6.1 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre data GSM8K"
      ],
      "metadata": {
        "id": "u9c7aPuIRR72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import instructor\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import List, TextIO\n",
        "\n",
        "import openai\n",
        "from datasets import load_dataset\n",
        "# from fire import Fire\n",
        "from pydantic import BaseModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def remove_substrings_with_double_angle_brackets(input_string):\n",
        "    # Define the pattern to match substrings within double angled brackets\n",
        "    pattern = r\"<<[^>]+>>\"\n",
        "    # Use the sub() function from the re module to replace matching substrings with an empty string\n",
        "    result = re.sub(pattern, \"\", input_string)\n",
        "    return result\n",
        "\n",
        "\n",
        "class ReasonSample(BaseModel):\n",
        "    question: str\n",
        "    explanation: str = \"\"\n",
        "    answer: str = \"\"\n",
        "    wrong_explanation: str = \"\"\n",
        "    wrong_answer: str = \"\"\n",
        "    pred: str = \"\"\n",
        "\n",
        "\n",
        "class ReasonData(BaseModel):\n",
        "    samples: List[ReasonSample]\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path: str):\n",
        "        samples = []\n",
        "        with open(path) as f:\n",
        "            for line in f:\n",
        "                raw = json.loads(line)\n",
        "                samples.append(ReasonSample(**raw))\n",
        "\n",
        "        return cls(samples=samples)\n",
        "\n",
        "    @classmethod\n",
        "    def load_gsm8k_test(cls, path: str = \"gsm8k\", subset: str = \"main\", split=\"test\"):\n",
        "        samples = []\n",
        "        for raw in load_dataset(path, subset, split=split):\n",
        "            explanation, answer = raw[\"answer\"].split(\"####\")\n",
        "            explanation = remove_substrings_with_double_angle_brackets(explanation)\n",
        "            samples.append(\n",
        "                ReasonSample(\n",
        "                    question=raw[\"question\"].strip(),\n",
        "                    explanation=explanation.strip(),\n",
        "                    answer=answer.strip(),\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return cls(samples=samples)\n",
        "\n",
        "    @classmethod\n",
        "    def load_gsm8k_incoherent_objects(cls, split: str = \"test\", sample: bool = False):\n",
        "        if split == \"train\" and sample:\n",
        "            samples = [\n",
        "                ReasonSample(\n",
        "                    question=\"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\",\n",
        "                    explanation=\"There are 15 trees originally. Then there were 21 trees after the Grove workers planted some more. So there must have been 21 - 15 = 6 trees that were planted.\",\n",
        "                    answer=\"6\",\n",
        "                    wrong_explanation=\"There are 21 - 15 = 6 trees originally. Then there were 15 trees after the Grove workers planted some more. So there must have been 21 trees that were planted.\",\n",
        "                    wrong_answer=\"21\",\n",
        "                ),\n",
        "                ReasonSample(\n",
        "                    question=\"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot??\",\n",
        "                    explanation=\"There are originally 3 cars. Then 2 more cars arrive. Now 3 + 2 = 5 cars are in the parking lot.\",\n",
        "                    answer=\"5\",\n",
        "                    wrong_explanation=\"There are originally 3 + 2 = 5 cars. Then 3 more cars arrive. Now 2 cars are in the parking lot\",\n",
        "                    wrong_answer=\"2\",\n",
        "                ),\n",
        "                ReasonSample(\n",
        "                    question=\"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\",\n",
        "                    explanation=\"Originally, Leah had 32 chocolates and her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39 pieces left in total.\",\n",
        "                    answer=\"39\",\n",
        "                    wrong_explanation=\"Originally, Leah had 32 + 42 = 74 chocolates and her sister had 32. So in total they had 74 - 35 = 39. After eating 35, they had 42 pieces left in total\",\n",
        "                    wrong_answer=\"42\",\n",
        "                ),\n",
        "                ReasonSample(\n",
        "                    question=\"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\",\n",
        "                    explanation=\"Jason had 20 lollipops originally. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8 lollipops.\",\n",
        "                    answer=\"8\",\n",
        "                    wrong_explanation=\"Jason had 20 - 12 = 8 lollipops originally. Then he had 20 after giving some to Denny. So he gave Denny 12 lollipops\",\n",
        "                    wrong_answer=\"12\",\n",
        "                ),\n",
        "            ]\n",
        "            return cls(samples=samples)\n",
        "        else:\n",
        "            return cls.load_gsm8k_test()\n",
        "\n",
        "    @classmethod\n",
        "    def load_from_name(cls, name: str, **kwargs):\n",
        "        if name == \"gsm8k\":\n",
        "            return cls.load_gsm8k_incoherent_objects(**kwargs)\n",
        "        else:\n",
        "            raise KeyError(name)\n",
        "\n",
        "\n",
        "class Prompter(BaseModel):\n",
        "    def run(self, data_train: ReasonData, sample_test: ReasonSample) -> str:\n",
        "        prompt = \"\"\n",
        "        for sample in data_train.samples:\n",
        "            prompt += f\"Question: {sample.question}\\n\"\n",
        "            prompt += f\"Answer: {sample.answer}\\n\\n\"\n",
        "\n",
        "        prompt += f\"Question: {sample_test.question}\\n\"\n",
        "        prompt += \"Answer: \"\n",
        "        return prompt\n",
        "\n",
        "    @staticmethod\n",
        "    def get_answer(text: str) -> str:\n",
        "        parts = text.split(\"Answer: \")\n",
        "        if len(parts) >= 2:\n",
        "            return parts[1]\n",
        "        else:\n",
        "            return text\n",
        "\n",
        "\n",
        "class ChainThoughtPrompter(Prompter):\n",
        "    def run(self, data_train: ReasonData, sample_test: ReasonSample) -> str:\n",
        "        prompt = \"\"\n",
        "        for sample in data_train.samples:\n",
        "            prompt += f\"Question: {sample.question}\\n\"\n",
        "            prompt += f\"Explanation: {sample.explanation}\\n\"\n",
        "            prompt += f\"Answer: {sample.answer}\\n\\n\"\n",
        "\n",
        "        prompt += f\"Question: {sample_test.question}\\n\"\n",
        "        prompt += \"Explanation: \"\n",
        "        return prompt\n",
        "\n",
        "    def get_explanation(self, text: str) -> str:\n",
        "        assert self is not None\n",
        "        return text.split(\"\\nAnswer: \")[0]\n",
        "\n",
        "\n",
        "class ContrastiveChainThoughtPrompter(Prompter):\n",
        "    def run(self, data_train: ReasonData, sample_test: ReasonSample) -> str:\n",
        "        prompt = \"\"\n",
        "        for sample in data_train.samples:\n",
        "            prompt += f\"Question: {sample.question}\\n\"\n",
        "            prompt += f\"Explanation: {sample.explanation}\\n\"\n",
        "            prompt += f\"Answer: {sample.answer}\\n\"\n",
        "            prompt += f\"Wrong explanation: {sample.wrong_explanation}\\n\"\n",
        "            prompt += f\"Wrong Answer: {sample.wrong_answer}\\n\\n\"\n",
        "\n",
        "        prompt += f\"Question: {sample_test.question}\\n\"\n",
        "        prompt += \"Explanation: \"\n",
        "        return prompt\n",
        "\n",
        "\n",
        "def select_prompter(name: str):\n",
        "    if name == \"standard\":\n",
        "        return Prompter()\n",
        "    if name == \"cot\":\n",
        "        return ChainThoughtPrompter()\n",
        "    if name == \"contrast_cot\":\n",
        "        return ContrastiveChainThoughtPrompter()\n",
        "    else:\n",
        "        raise KeyError(name)\n"
      ],
      "metadata": {
        "id": "7lYVwDEeRZkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = ReasonData.load_from_name('gsm8k', split=\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "876e5dcb2d154e7f9ea5f0aca61c318f",
            "6b885ba8603046fc913e763529ffe6cb",
            "4ae2a4dcd4ad4e3bb4fa687287fef75f",
            "1a1507f3178640c3ae2fb2ed86d13d92",
            "3564fac9d73a454596bb8ba6d09b322c",
            "75ee0b8635144abba3d5d72896e831c1",
            "cae23f6bc57c4f05a2a66f21479d08d9",
            "4212ffa8867e45c5bc9e8a1e0eae2727",
            "c43bcc23efd049898e977dc2b4babbc0",
            "6b0f57a0d54048c294d58103d5c1d5ff",
            "d381e60ce6674b3697c9f60494d8a76a",
            "3343ae1ee10c4a65b0153c236dc6428a",
            "8f20af389cdc48f1905bff84c62efee6",
            "337098b9b45c46f6929fa4c8c8197a84",
            "15332170c70e4f7c888d6bbe2f64ef78",
            "6d6d252f9ef1423392498e5adc4c134d",
            "593cdd3871b0460db8a0f365c0791ba5",
            "1811f55e1c1c4db6af73790b6b24c8a9",
            "761aff5619984cfbbd51c169e28e3e09",
            "303e7c747d3e47139665045fe2867bb8",
            "6eab52850f004dedb47488a90a9f1e35",
            "b65b404f54384587935e46ba3f73e02d",
            "5b1c4dc336654b7abc4a6936875a8ea0",
            "7b159ee92e324ffba8c2ae882e4f7075",
            "bdc85e3fb81346afa7eade27d980ec94",
            "228c25c6d34a40a3888d6dee0d3f6d87",
            "015b8fc4c6bf4309a997628d03b09904",
            "a72e7fdc60a74c80a0d79858a98ebf19",
            "dcfe543a35714b58957b3d3145fd5a0e",
            "c87406ddc5af4a2b88a2cae590376362",
            "41b8a395b6d542e4a761a690608d037c",
            "d75bb5f2a73947099321b875c14cd452",
            "617787300048487a92c9a75dcbeb328d",
            "5a6d95e682ef48d6a7231dfcbb079b9b",
            "e04d362d95e3499ea28152c537e6e5a7",
            "96e57470d1db43adbf17cd9a44d71151",
            "39e8a53906724dcda1d5e2b07394d0ad",
            "805066eebe5142ed8abcc514b922df66",
            "cb85ffdccd4a49c69159921fdf258e6e",
            "a98ecaa08a474d19ba6eed9f839e96a7",
            "f0b698d5364e42bda7351e00ed6a2cbe",
            "48c671c8822e4c57bc73d6ea0a6bd070",
            "1763e0e18301478bb61e8ea5ef8ad05c",
            "1623a50bf22c493580944cc645b1a7a1",
            "56e96c400265447a935278adb1e1ae51",
            "4ceb8580fd6b43e4baccad792df1694e",
            "40c490b668534a4bb570850c933df81f",
            "9734c097136f4bc8b197170ddbcc1021",
            "3e57986017834fd99e742ffe259f06d2",
            "a4a35db3b4a44677a5c76c19570f9535",
            "41bcb132d4ba48f5a5f05d50f22d121e",
            "63b6e7eff5194e8aa6dfe0c773bbd97c",
            "ad3e07c96b104910b8c8b95fc6d47ba6",
            "232b1ec4cae34ade8821cc557441d7f5",
            "b7b64e0fa85c4d1f8117831a23dbb1e8"
          ]
        },
        "id": "hQUTdDBHf9tz",
        "outputId": "ed8164c0-9191-434d-dbb7-49cb4d45f5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "876e5dcb2d154e7f9ea5f0aca61c318f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3343ae1ee10c4a65b0153c236dc6428a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b1c4dc336654b7abc4a6936875a8ea0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a6d95e682ef48d6a7231dfcbb079b9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56e96c400265447a935278adb1e1ae51"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test.samples[0].question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "mmUksWJSgANz",
        "outputId": "4b9d7ee8-e5cd-4dd9-f115-1797e7e6bed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = ReasonData.load_from_name('gsm8k', split=\"train\", sample=True)"
      ],
      "metadata": {
        "id": "iDwqG1IsSM1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.samples[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7nFN7nuRzsT",
        "outputId": "9b3d6b7a-34ac-4234-e172-6b7c68a29d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ReasonSample(question='There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?', explanation='There are 15 trees originally. Then there were 21 trees after the Grove workers planted some more. So there must have been 21 - 15 = 6 trees that were planted.', answer='6', wrong_explanation='There are 21 - 15 = 6 trees originally. Then there were 15 trees after the Grove workers planted some more. So there must have been 21 trees that were planted.', wrong_answer='21', pred='')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding Step 1 : Mixture of Reasoning Experts"
      ],
      "metadata": {
        "id": "scxsjbDplvU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import instructor\n",
        "from pydantic import BaseModel\n",
        "from collections import defaultdict, Counter\n",
        "import openai\n",
        "import asyncio\n",
        "from textwrap import dedent\n",
        "import math\n",
        "\n",
        "client = openai.AsyncOpenAI(api_key='sk-U7ti37t3osaeWme7m88923xFY2UMGVQLkeydTAywi3xI7TOP',\n",
        "                                              base_url=\"https://api.chatanywhere.tech/v1\")\n",
        "client = instructor.from_openai(client)\n",
        "\n",
        "class Response(BaseModel):\n",
        "    chain_of_thought: list[str]\n",
        "    answer: int\n",
        "\n",
        "\n",
        "class ResponseScore(BaseModel):\n",
        "    query: str\n",
        "    response: Response\n",
        "    score: float\n",
        "\n",
        "    def format_response(self):\n",
        "        return dedent(\n",
        "            f\"\"\"\n",
        "            Q: {self.query}\n",
        "            A: {''.join(self.response.chain_of_thought)}. Therefore the answer is {self.response.answer}.\n",
        "            \"\"\"\n",
        "        )\n",
        "def cosine_similarity(vec1: list[float], vec2: list[float]):\n",
        "    dot_product = sum(a * b for a, b in zip(vec1, vec2))\n",
        "    magnitude1 = math.sqrt(sum(a * a for a in vec1))\n",
        "    magnitude2 = math.sqrt(sum(b * b for b in vec2))\n",
        "\n",
        "    if magnitude1 * magnitude2 == 0:\n",
        "        return 0  # Handle the case of zero vectors\n",
        "\n",
        "    return dot_product / (magnitude1 * magnitude2)\n",
        "\n",
        "\n",
        "def score_repetitiveness(prediction: Response):\n",
        "\n",
        "    embedding = openai.OpenAI(api_key='sk-U7ti37t3osaeWme7m88923xFY2UMGVQLkeydTAywi3xI7TOP',\n",
        "                                              base_url=\"https://api.chatanywhere.tech/v1\").embeddings.create(input=prediction.chain_of_thought, model=\"text-embedding-3-small\"\n",
        "    )\n",
        "    embedding = [item.embedding for item in embedding.data]\n",
        "    print(len(embedding))\n",
        "    ttl = 0\n",
        "    num_comparisons = 0\n",
        "    for idx in range(len(embedding)):\n",
        "        for idx2 in range(idx + 1, len(embedding)):\n",
        "            ttl += cosine_similarity(embedding[idx], embedding[idx2])\n",
        "            num_comparisons += 1\n",
        "    print(num_comparisons)\n",
        "    return 2*ttl/(num_comparisons)*(num_comparisons - 1) if num_comparisons > 0 else 0\n",
        "\n",
        "async def generate_cot_response(query: str) -> tuple[Response, str]:\n",
        "    return (\n",
        "        await client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": query}],\n",
        "            response_model=Response,\n",
        "            temperature=0.4,\n",
        "        ),\n",
        "        query,\n",
        "    )\n",
        "\n",
        "\n",
        "async def generate_batch_cot_responses(\n",
        "    queries: list[str], m: int\n",
        ") -> list[tuple[Response, str]]:\n",
        "    coros = [generate_cot_response(query) for query in queries for _ in range(m)]\n",
        "    return await asyncio.gather(*coros)\n",
        "\n",
        "def score_entropy(predictions: list[Response]):\n",
        "    counter = Counter([prediction.answer for prediction in predictions])\n",
        "\n",
        "    prob = [counter[i] / len(predictions) for i in counter]\n",
        "\n",
        "    numer = -sum([p * math.log(p) for p in prob])\n",
        "    denom = math.log(len(predictions))\n",
        "\n",
        "    return numer / denom\n",
        "\n",
        "\n",
        "def score_responses(\n",
        "    predictions: list[tuple[Response, str]], trade_off_param: float\n",
        ") -> list[ResponseScore]:\n",
        "    query_to_responses: dict[str, list[Response]] = defaultdict(list)\n",
        "    for prediction, query in predictions:\n",
        "        query_to_responses[query].append(prediction)\n",
        "\n",
        "    query_to_entropy = {\n",
        "        query: score_entropy(predictions)\n",
        "        for query, predictions in query_to_responses.items()\n",
        "    }\n",
        "\n",
        "    return [\n",
        "        ResponseScore(\n",
        "            query=query,\n",
        "            response=prediction,\n",
        "            score=query_to_entropy[query]\n",
        "            + trade_off_param * score_repetitiveness(prediction),\n",
        "        )\n",
        "        for prediction, query in predictions\n",
        "    ]\n",
        "\n",
        "\n",
        "def get_top_k_examples(queries: list[ResponseScore], k: int):\n",
        "    \"\"\"\n",
        "    This gets the top k responses that have the minimum possible score\n",
        "    \"\"\"\n",
        "    sorted_responses = sorted(queries, key=lambda x: x.score)\n",
        "    return sorted_responses[:k]\n",
        "\n",
        "\n",
        "async def generate_answer_with_examples(query: str, examples: list[ResponseScore]):\n",
        "    formatted_examples = \"\\n\".join([example.format_response() for example in examples])\n",
        "    return await client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": dedent(\n",
        "                    f\"\"\"\n",
        "                You are a world class AI system that excels at answering user queries\n",
        "\n",
        "                <query>\n",
        "                {query}\n",
        "                </query>\n",
        "\n",
        "                <examples>\n",
        "                {formatted_examples}\n",
        "                </examples>\n",
        "                \"\"\"\n",
        "                ),\n",
        "            }\n",
        "        ],\n",
        "        response_model=Response,\n",
        "    )\n",
        "\n",
        "\n",
        "async def generate_final_answers(\n",
        "    query: str, examples: list[ResponseScore], number_samples: int\n",
        "):\n",
        "    coros = [\n",
        "        generate_answer_with_examples(query, examples) for _ in range(number_samples)\n",
        "    ]\n",
        "\n",
        "    return await asyncio.gather(*coros)"
      ],
      "metadata": {
        "id": "V5FwWn5_hqX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "loop = asyncio.get_event_loop()\n",
        "# Apply nest_asyncio to the loop\n",
        "nest_asyncio.apply(loop)\n",
        "\n",
        "# Run the coroutine using the loop's run_until_complete method\n",
        "m = 2  # Number of Reasoning Chains per example ( Step 1 )\n",
        "k = 3  # Number of Examples to include in final prompt (Step 2)\n",
        "n = 2  # Number of Reasoning Chains For Self-Consistency ( Step 2 )\n",
        "\n",
        "# Step 1 : Generate the examples\n",
        "query = (\n",
        "    \"The schools debate team had 5 boys and 40 girls on it. \"\n",
        "    \"If they were split into groups of 9 how many groups \"\n",
        "    \"could they make?\"\n",
        ")\n",
        "\n",
        "example_questions = [\n",
        "    (\n",
        "        \"Debby's class is going on a field trip to the zoo. \"\n",
        "        \"If each van can hold 4 people and there are 2 students \"\n",
        "        \"and 6 adults going, how many vans will they need?\"\n",
        "    ),\n",
        "    (\n",
        "        \"Nancy had 80 files on her computer. She deleted 31 of \"\n",
        "        \"them and put the rest into folders with 7 files in each \"\n",
        "        \"one. How many folders did Nancy end up with?\"\n",
        "    ),\n",
        "    (\n",
        "        \"At the arcade, Tom won 32 tickets playing 'whack a mole' \"\n",
        "        \"and 25 tickets playing 'skee ball'. If he spent 7 of his \"\n",
        "        \"tickets on a hat, how many tickets does Tom have left?\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "m = 2  # Number of Reasoning Chains per example ( Step 1 )\n",
        "k = 3  # Number of Examples to include in final prompt (Step 2)\n",
        "n = 2  # Number of Reasoning Chains For Self-Consistency ( Step 2 )\n",
        "\n",
        "# Step 1 : Generate the examples\n",
        "responses = loop.run_until_complete(generate_batch_cot_responses(example_questions, m))\n",
        "scored_responses = score_responses(responses, 0.2)\n",
        "\n",
        "chosen_examples = get_top_k_examples(scored_responses, k)\n",
        "\n",
        "# Step 2 : Run Self-Consistency\n",
        "final_responses = loop.run_until_complete(generate_final_answers(query, chosen_examples, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3477yKbjrab",
        "outputId": "379e5bcc-6232-4e25-916c-343e08fba071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "3\n",
            "4\n",
            "6\n",
            "5\n",
            "10\n",
            "4\n",
            "6\n",
            "5\n",
            "10\n",
            "5\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "responses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wICew3R3tMdh",
        "outputId": "42362879-d536-4559-edc3-a4f039b16e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Response(chain_of_thought=['Calculate the total number of people going on the trip: 2 students + 6 adults = 8 people.', 'Determine how many vans are needed by dividing the total number of people by the capacity of each van: 8 people ÷ 4 people per van = 2 vans.', 'Since the number of vans must be a whole number, and 8 is exactly divisible by 4, no additional van is needed.'], answer=2),\n",
              "  \"Debby's class is going on a field trip to the zoo. If each van can hold 4 people and there are 2 students and 6 adults going, how many vans will they need?\"),\n",
              " (Response(chain_of_thought=['Total people going on the trip = number of students + number of adults = 2 + 6 = 8', 'Each van can hold 4 people.', 'To find the number of vans needed, divide the total number of people by the capacity of each van: 8 / 4 = 2.', 'Since 8 is exactly divisible by 4, they will need 2 vans.'], answer=2),\n",
              "  \"Debby's class is going on a field trip to the zoo. If each van can hold 4 people and there are 2 students and 6 adults going, how many vans will they need?\"),\n",
              " (Response(chain_of_thought=['Nancy started with 80 files.', 'She deleted 31 files, so we need to subtract 31 from 80.', '80 - 31 = 49 files remaining.', 'Nancy then put the remaining 49 files into folders with 7 files in each folder.', 'To find the number of folders, we divide the remaining files by the number of files per folder: 49 / 7.'], answer=7),\n",
              "  'Nancy had 80 files on her computer. She deleted 31 of them and put the rest into folders with 7 files in each one. How many folders did Nancy end up with?'),\n",
              " (Response(chain_of_thought=['Nancy initially had 80 files.', 'She deleted 31 files, so the number of files left is 80 - 31 = 49 files.', 'Nancy then put the remaining files into folders with 7 files in each folder.', 'To find the number of folders, we divide the number of remaining files by the number of files per folder: 49 files ÷ 7 files/folder = 7 folders.'], answer=7),\n",
              "  'Nancy had 80 files on her computer. She deleted 31 of them and put the rest into folders with 7 files in each one. How many folders did Nancy end up with?'),\n",
              " (Response(chain_of_thought=[\"Tom won 32 tickets from 'whack a mole'.\", \"Tom won 25 tickets from 'skee ball'.\", 'Total tickets won = 32 + 25 = 57 tickets.', 'Tom spent 7 tickets on a hat.', 'Tickets left = Total tickets - Tickets spent = 57 - 7.'], answer=50),\n",
              "  \"At the arcade, Tom won 32 tickets playing 'whack a mole' and 25 tickets playing 'skee ball'. If he spent 7 of his tickets on a hat, how many tickets does Tom have left?\"),\n",
              " (Response(chain_of_thought=[\"Tom won 32 tickets from 'whack a mole'.\", \"Tom won 25 tickets from 'skee ball'.\", 'Total tickets won = 32 + 25 = 57 tickets.', 'Tom spent 7 tickets on a hat.', 'Tickets left = Total tickets - Tickets spent = 57 - 7.'], answer=50),\n",
              "  \"At the arcade, Tom won 32 tickets playing 'whack a mole' and 25 tickets playing 'skee ball'. If he spent 7 of his tickets on a hat, how many tickets does Tom have left?\")]"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWtP77Q8s9kW",
        "outputId": "c0a8dfd5-7d63-45a2-e1e6-7829188943be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ResponseScore(query=\"Debby's class is going on a field trip to the zoo. If each van can hold 4 people and there are 2 students and 6 adults going, how many vans will they need?\", response=Response(chain_of_thought='First, we need to determine the total number of people going on the field trip. There are 2 students and 6 adults, so we add these together: 2 + 6 = 8 people in total. Next, we know that each van can hold 4 people. To find out how many vans are needed, we divide the total number of people by the capacity of each van: 8 ÷ 4 = 2 vans. Therefore, they will need 2 vans for the trip.', answer=2), score=0.0),\n",
              " ResponseScore(query=\"Debby's class is going on a field trip to the zoo. If each van can hold 4 people and there are 2 students and 6 adults going, how many vans will they need?\", response=Response(chain_of_thought='First, we need to calculate the total number of people going on the field trip. There are 2 students and 6 adults, so we add these numbers together: 2 + 6 = 8 people. Next, we need to determine how many vans are required to transport these 8 people. Since each van can hold 4 people, we divide the total number of people by the number of people each van can hold: 8 / 4 = 2 vans. Therefore, they will need 2 vans for the trip.', answer=2), score=0.0),\n",
              " ResponseScore(query='Nancy had 80 files on her computer. She deleted 31 of them and put the rest into folders with 7 files in each one. How many folders did Nancy end up with?', response=Response(chain_of_thought='First, we need to find out how many files Nancy has left after deleting 31 files from the original 80. This can be calculated as: 80 - 31 = 49 files remaining. Next, we need to determine how many folders she can create with these remaining files, given that each folder contains 7 files. We can find the number of folders by dividing the remaining files by the number of files per folder: 49 / 7 = 7 folders. Therefore, Nancy ended up with 7 folders.', answer=7), score=0.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x9X_9CR9C5-"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "import instructor\n",
        "from textwrap import dedent\n",
        "\n",
        "client1 = OpenAI(api_key='sk-RYiDonFCU85Bfr242X2POvCBhlhfHlz8knZQoVjWVJw180s6',\n",
        "                                              base_url=\"https://api.chatanywhere.tech/v1\")\n",
        "client1 = instructor.from_openai(client1)\n",
        "\n",
        "\n",
        "class MultihopExpert(BaseModel):\n",
        "    chain_of_thought: list[str]\n",
        "    answer: str\n",
        "\n",
        "\n",
        "class FactualExpert(BaseModel):\n",
        "    chain_of_thought: list[str]\n",
        "    answer: str\n",
        "\n",
        "class MathExpert(BaseModel):\n",
        "    chain_of_thought: list[str] = Field(description=\"Incorrect reasoning for the answer\")\n",
        "    answer: str\n",
        "\n",
        "class CommonsenseExpert(BaseModel):\n",
        "    chain_of_thought: list[str]\n",
        "    answer: str\n",
        "\n",
        "class ModelScore(BaseModel):\n",
        "    score: float = Field(ge=0, lt=1)\n",
        "\n",
        "\n",
        "def query_factual_expert(query: str, evidence: list[str]):\n",
        "    formatted_evidence = \"\\n-\".join(evidence)\n",
        "    return client1.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        response_model=FactualExpert,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": dedent(\n",
        "                    f\"\"\"\n",
        "                <query>\n",
        "                {query}\n",
        "                </query>\n",
        "\n",
        "                <evidences>\n",
        "                {formatted_evidence}\n",
        "                </evidences>\n",
        "                \"\"\"\n",
        "                ),\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "\n",
        "def query_multihop_expert(query: str):\n",
        "    return client1.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        response_model=MultihopExpert,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": dedent(\n",
        "                    f\"\"\"\n",
        "                <query>\n",
        "                {query}\n",
        "                </query>\n",
        "                \"\"\"\n",
        "                ),\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "\n",
        "def query_math_expert(query: str, sample):\n",
        "  return client1.chat.completions.create(\n",
        "      model='gpt-4o-mini',\n",
        "      response_model=MathExpert,\n",
        "      messages=[\n",
        "          {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": dedent(\n",
        "                    f\"\"\"\n",
        "            <prompt>\n",
        "                <role>system</role>\n",
        "                <context>\n",
        "                You are an expert question answering AI System.\n",
        "\n",
        "                You are about to be given some examples of incorrect\n",
        "                and correct reasoning for a question. You will then\n",
        "                be asked to correctly reason through another question\n",
        "                to generate a valid response.\n",
        "                </context>\n",
        "\n",
        "                <question>{sample.question}</question>\n",
        "\n",
        "                <Explanations>\n",
        "                    {sample.explanation}\n",
        "                    {sample.wrong_explanation}\n",
        "                </Explanations>\n",
        "                <question>{query}</question>\n",
        "            </prompt>\n",
        "            \"\"\"\n",
        "                ),\n",
        "            }\n",
        "      ]\n",
        "\n",
        "  )\n",
        "\n",
        "def score_answer(query: str, answer: str):\n",
        "    return client1.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        response_model=ModelScore,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"You are a helpful assistant that scores\n",
        "                answers based on well they are able to answer a\n",
        "                specific user query\"\"\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "                <user query>\n",
        "                {query}\n",
        "                </user query>\n",
        "\n",
        "                <response>\n",
        "                {answer}\n",
        "                </response>\n",
        "                \"\"\",\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "\n",
        "def query_commonsense_expert(query: str, evidence: list[str]):\n",
        "    formatted_evidence = \"\\n-\".join(evidence)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.samples[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6506oRhHbtri",
        "outputId": "1908e2d4-e3bf-44bc-8982-8ff94a717ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ReasonSample(question='There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?', explanation='There are 15 trees originally. Then there were 21 trees after the Grove workers planted some more. So there must have been 21 - 15 = 6 trees that were planted.', answer='6', wrong_explanation='There are 21 - 15 = 6 trees originally. Then there were 15 trees after the Grove workers planted some more. So there must have been 21 trees that were planted.', wrong_answer='21', pred='')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # query = \"\"\"Who's the original singer of Help Me Make It\n",
        "    # Through The Night?\"\"\"\n",
        "\n",
        "    evidences = [\n",
        "        \"\"\"Help Me Make It Through The Night is a country\n",
        "        music ballad written and composed by Kris Kristofferson\n",
        "        and released on his 1970 album 'Kristofferson'\"\"\"\n",
        "    ]\n",
        "\n",
        "    threshold = 0.8\n",
        "\n",
        "    factual_expert_output = query_factual_expert(query, evidences)\n",
        "    print(factual_expert_output.model_dump_json(indent=2))\n",
        "\n",
        "    multihop_expert_output = query_multihop_expert(query)\n",
        "    print(multihop_expert_output.model_dump_json(indent=2))\n",
        "\n",
        "    math_expert_output = query_math_expert(query, data_train.samples[0])\n",
        "    print(math_expert_output.model_dump_json(indent=2))\n",
        "\n",
        "    factual_expert_score = score_answer(query, factual_expert_output.answer)\n",
        "    multihop_expert_score = score_answer(query, multihop_expert_output.answer)\n",
        "    math_expert_score = score_answer(query, math_expert_output.answer)\n",
        "\n",
        "    if max(factual_expert_score.score, multihop_expert_score.score) < threshold:\n",
        "        answer = \"Abstaining from responding\"\n",
        "    elif factual_expert_score.score > multihop_expert_score.score:\n",
        "        answer = factual_expert_output.answer\n",
        "    else:\n",
        "        answer = multihop_expert_output.answer\n",
        "\n",
        "    print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFuv67eKZRU5",
        "outputId": "c361d0ea-235c-4fa3-9e8a-70eb076c3cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"chain_of_thought\": [\n",
            "    \"Calculate the total number of students in the debate team by adding the number of boys and girls.\",\n",
            "    \"Total students = 5 boys + 40 girls = 45 students.\",\n",
            "    \"Next, determine how many groups of 9 can be formed with 45 students by dividing 45 by 9.\",\n",
            "    \"Groups = 45 students / 9 students per group.\"\n",
            "  ],\n",
            "  \"answer\": \"5 groups\"\n",
            "}\n",
            "{\n",
            "  \"chain_of_thought\": [\n",
            "    \"First, we need to determine the total number of students on the debate team.\",\n",
            "    \"There are 5 boys and 40 girls. So, total students = 5 + 40 = 45.\",\n",
            "    \"Next, we want to split these 45 students into groups of 9.\",\n",
            "    \"To find the number of groups, we divide the total number of students by the group size: 45 / 9.\",\n",
            "    \"Calculating this gives us 5.\"\n",
            "  ],\n",
            "  \"answer\": \"5\"\n",
            "}\n",
            "{\n",
            "  \"chain_of_thought\": [\n",
            "    \"The debate team has a total of 5 boys and 40 girls, which sums up to 5 + 40 = 45 members.\",\n",
            "    \"If the team is split into groups of 9, we need to determine how many full groups of 9 can be formed from 45 members.\",\n",
            "    \"To find out how many groups can be made, we calculate 45 divided by 9, which is 45 / 9 = 5.\"\n",
            "  ],\n",
            "  \"answer\": \"5 groups\"\n",
            "}\n",
            "Abstaining from responding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(factual_expert_output.model_dump_json(indent=2),factual_expert_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUd0JZmifnLu",
        "outputId": "e3f8fe23-1193-4f5a-c267-1d3056fe90ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"answer\": \"The debate team has a total of 5 boys + 40 girls = 45 members. If they split into groups of 9, we can divide 45 by 9. \\n\\n45 ÷ 9 = 5. \\n\\nThus, they can make 5 groups.\"\n",
            "} score=0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(multihop_expert_output.model_dump_json(indent=2),multihop_expert_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_pzqZb_e9bw",
        "outputId": "5fd9b734-e2b8-47e9-bb59-40265831bf74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"chain_of_thought\": \"The song 'Help Me Make It Through The Night' was originally performed by the artist Sammi Smith. It was released in 1970 and became a significant hit.\",\n",
            "  \"answer\": \"Sammi Smith\"\n",
            "} score=0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(math_expert_output.model_dump_json(indent=2),math_expert_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuNF_IkXfxRE",
        "outputId": "0b24e5c9-b2e7-4116-d802-fa00d4d4f508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"chain_of_thought\": \"The song 'Help Me Make It Through The Night' was originally sung by Sammi Smith in 1970, making her the original artist. It's important to identify the time frame as well as the artist's claim to the song.\",\n",
            "  \"correct_answer\": \"Sammi Smith\"\n",
            "} score=0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\""
      ],
      "metadata": {
        "id": "2Rafjs8RgIe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factual_expert_output = query_factual_expert(query, evidences)\n",
        "print(factual_expert_output.model_dump_json(indent=2))\n",
        "\n",
        "multihop_expert_output = query_multihop_expert(query)\n",
        "print(multihop_expert_output.model_dump_json(indent=2))\n",
        "\n",
        "math_expert_output = query_math_expert(query, data_train.samples[0])\n",
        "print(math_expert_output.model_dump_json(indent=2))\n",
        "\n",
        "factual_expert_score = score_answer(query, factual_expert_output.answer)\n",
        "multihop_expert_score = score_answer(query, multihop_expert_output.answer)\n",
        "math_expert_score = score_answer(query, math_expert_output.answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBvvvkSZgROm",
        "outputId": "1d8837c1-dbbb-4d4b-b067-82832b876257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"chain_of_thought\": [\n",
            "    \"Janet’s ducks lay 16 eggs per day.\",\n",
            "    \"She eats 3 eggs for breakfast every morning, leaving her with 16 - 3 = 13 eggs.\",\n",
            "    \"She bakes 4 muffins with 4 eggs, leaving her with 13 - 4 = 9 eggs.\",\n",
            "    \"The remainder of the eggs that she sells is 9 eggs.\",\n",
            "    \"She sells each egg for $2, so her total earnings from selling the eggs is 9 * 2 = 18.\"\n",
            "  ],\n",
            "  \"answer\": \"18\"\n",
            "}\n",
            "{\n",
            "  \"chain_of_thought\": [\n",
            "    \"Janet has 16 duck eggs.\",\n",
            "    \"She eats 3 eggs for breakfast, so remaining eggs after breakfast = 16 - 3 = 13 eggs.\",\n",
            "    \"She bakes muffins with 4 eggs, so remaining eggs after baking = 13 - 4 = 9 eggs.\",\n",
            "    \"Janet sells the remaining eggs (9) at the farmers' market for $2 each.\",\n",
            "    \"Total earnings from selling eggs = 9 eggs * $2/egg = $18.\"\n",
            "  ],\n",
            "  \"answer\": \"18\"\n",
            "}\n",
            "{\n",
            "  \"chain_of_thought\": [\n",
            "    \"Janet's ducks lay 16 eggs every day.\",\n",
            "    \"She eats 3 eggs for breakfast, which means she has 16 - 3 = 13 eggs left.\",\n",
            "    \"She bakes muffins with 4 eggs, so now she has 13 - 4 = 9 eggs remaining.\",\n",
            "    \"Janet sells those 9 eggs at the farmers' market for $2 each, so she makes 9 * 2 = 18 dollars.\"\n",
            "  ],\n",
            "  \"answer\": \"18\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = 2  # Number of Reasoning Chains per example ( Step 1 )\n",
        "k = 3  # Number of Examples to include in final prompt (Step 2)\n",
        "n = 2  # Number of Reasoning Chains For Self-Consistency ( Step 2 )\n",
        "\n",
        "# Step 1 : Generate the examples\n",
        "responses = loop.run_until_complete(generate_batch_cot_responses(example_questions, m))\n",
        "scored_responses = score_responses(responses, 0.2)\n",
        "\n",
        "chosen_examples = get_top_k_examples(scored_responses, k)\n",
        "\n",
        "# Step 2 : Run Self-Consistency\n",
        "final_responses = loop.run_until_complete(generate_final_answers(query, chosen_examples, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtCouLZm9XTP",
        "outputId": "6db533b3-00aa-4c49-b49d-255c0d21f3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "5\n",
            "10\n",
            "4\n",
            "6\n",
            "5\n",
            "10\n",
            "5\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "commonsense_expert_output = final_responses[0]\n",
        "math_expert_score = score_answer(query, commonsense_expert_output.answer)"
      ],
      "metadata": {
        "id": "l_PkfriQmMCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(factual_expert_output.model_dump_json(indent=2),factual_expert_score)\n",
        "print(multihop_expert_output.model_dump_json(indent=2),multihop_expert_score)\n",
        "print(math_expert_output.model_dump_json(indent=2),math_expert_score)\n",
        "print(commonsense_expert_output.model_dump_json(indent=2),math_expert_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-Ceapb1gXsT",
        "outputId": "338b1087-4bce-4003-d79e-545a69d18d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"chain_of_thought\": [\n",
            "    \"Janet’s ducks lay 16 eggs per day.\",\n",
            "    \"She eats 3 eggs for breakfast every morning, leaving her with 16 - 3 = 13 eggs.\",\n",
            "    \"She bakes 4 muffins with 4 eggs, leaving her with 13 - 4 = 9 eggs.\",\n",
            "    \"The remainder of the eggs that she sells is 9 eggs.\",\n",
            "    \"She sells each egg for $2, so her total earnings from selling the eggs is 9 * 2 = 18.\"\n",
            "  ],\n",
            "  \"answer\": \"18\"\n",
            "} score=0.1\n",
            "{\n",
            "  \"chain_of_thought\": [\n",
            "    \"Janet has 16 duck eggs.\",\n",
            "    \"She eats 3 eggs for breakfast, so remaining eggs after breakfast = 16 - 3 = 13 eggs.\",\n",
            "    \"She bakes muffins with 4 eggs, so remaining eggs after baking = 13 - 4 = 9 eggs.\",\n",
            "    \"Janet sells the remaining eggs (9) at the farmers' market for $2 each.\",\n",
            "    \"Total earnings from selling eggs = 9 eggs * $2/egg = $18.\"\n",
            "  ],\n",
            "  \"answer\": \"18\"\n",
            "} score=0.0\n",
            "{\n",
            "  \"chain_of_thought\": [\n",
            "    \"Janet's ducks lay 16 eggs every day.\",\n",
            "    \"She eats 3 eggs for breakfast, which means she has 16 - 3 = 13 eggs left.\",\n",
            "    \"She bakes muffins with 4 eggs, so now she has 13 - 4 = 9 eggs remaining.\",\n",
            "    \"Janet sells those 9 eggs at the farmers' market for $2 each, so she makes 9 * 2 = 18 dollars.\"\n",
            "  ],\n",
            "  \"answer\": \"18\"\n",
            "} score=0.1\n",
            "{\n",
            "  \"chain_of_thought\": [\n",
            "    \"Janet's ducks lay a total of 16 eggs per day.\",\n",
            "    \"She eats 3 eggs for breakfast and bakes with 4 eggs, totaling 3 + 4 = 7 eggs consumed by her.\",\n",
            "    \"To find out how many eggs she sells, subtract the eggs she consumed from the total: 16 - 7 = 9 eggs remain.\",\n",
            "    \"Janet sells these 9 eggs at the farmers' market for $2 each.\",\n",
            "    \"To calculate her daily earnings: 9 eggs * $2/egg = $18.\"\n",
            "  ],\n",
            "  \"answer\": 18\n",
            "} score=0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rep = []\n",
        "rep.append((factual_expert_output))\n",
        "rep.append((multihop_expert_output))\n",
        "rep.append((math_expert_output))\n",
        "rep.append((commonsense_expert_output))"
      ],
      "metadata": {
        "id": "6ReihyRxtWNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding Step 2:  Chọn câu hỏi đúng bằng random forest classifier"
      ],
      "metadata": {
        "id": "riSzbBZOlrQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Việc sử dụng random forest tương đối khó khi cần dữ liệu để huấn luyện một model sau đó mới có thể phân loại câu hỏi chính xác nhất\n",
        "\n",
        "xem thêm [code](https://github.com/NoviScl/MoRE/tree/main):\n",
        "\n",
        "Thay vào đó có thể sử dụng chọn câu hỏi bằng sử dụng entropy and Repetitiveness"
      ],
      "metadata": {
        "id": "nS8GUmz9rypf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOHooCPotvEV",
        "outputId": "5a5a9595-a160-4aa1-f78e-83e931567aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[FactualExpert(chain_of_thought='To find the total number of members in the debate team, we add the number of boys and girls together. There are 5 boys and 40 girls, so the total is: 5 + 40 = 45. Next, we need to determine how many groups of 9 can be made from these 45 members. We do this by dividing the total number of members by the size of each group: 45 ÷ 9 = 5. Therefore, the team can make 5 groups of 9 members each.', answer='5'),\n",
              " MultihopExpert(chain_of_thought='First, we need to determine the total number of students in the debate team. There are 5 boys and 40 girls, so we add them together: 5 + 40 = 45 students in total. Next, we want to find out how many groups of 9 can be made from these 45 students. To do this, we divide the total number of students by the group size: 45 ÷ 9 = 5 groups. Therefore, the number of groups that can be made is 5.', answer='5'),\n",
              " MathExpert(chain_of_thought='The total number of students on the debate team is 5 boys + 40 girls = 45 students. If they are split into groups of 9, we need to divide 45 by 9. The calculation is 45 ÷ 9 = 5. Therefore, they can make 5 groups of 9.', answer='5 groups'),\n",
              " Response(chain_of_thought='First, we need to calculate the total number of students in the debate team by adding the number of boys and girls: 5 boys + 40 girls = 45 students. Next, we divide the total number of students by the number of students in each group, which is 9, to find out how many groups can be made: 45 / 9 = 5 groups.', answer=5)]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "responses[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS6wIF_1zCjS",
        "outputId": "08c6f39b-7e33-461e-b3a6-8141a793c8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Response(chain_of_thought='First, we need to determine the total number of people going on the field trip. There are 2 students and 6 adults, so we add these together: 2 + 6 = 8 people in total. Next, we know that each van can hold 4 people. To find out how many vans are needed, we divide the total number of people by the capacity of each van: 8 ÷ 4 = 2 vans. Therefore, they will need 2 vans for the trip.', answer=2),\n",
              " \"Debby's class is going on a field trip to the zoo. If each van can hold 4 people and there are 2 students and 6 adults going, how many vans will they need?\")"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResponseScore(BaseModel):\n",
        "    query: str\n",
        "    response: Response\n",
        "    score: float\n",
        "\n",
        "    def format_response(self):\n",
        "        return dedent(\n",
        "            f\"\"\"\n",
        "            Q: {self.query}\n",
        "            A: {''.join(self.response.chain_of_thought)}. Therefore the answer is {self.response.answer}.\n",
        "            \"\"\"\n",
        "        )"
      ],
      "metadata": {
        "id": "pPP7UaSExveY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for re in rep:\n",
        "  print(re.chain_of_thought)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kvtoyuV0M3-",
        "outputId": "c48f9532-5984-4bad-defb-1e9e37a733dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find the total number of members in the debate team, we add the number of boys and girls together. There are 5 boys and 40 girls, so the total is: 5 + 40 = 45. Next, we need to determine how many groups of 9 can be made from these 45 members. We do this by dividing the total number of members by the size of each group: 45 ÷ 9 = 5. Therefore, the team can make 5 groups of 9 members each.\n",
            "First, we need to determine the total number of students in the debate team. There are 5 boys and 40 girls, so we add them together: 5 + 40 = 45 students in total. Next, we want to find out how many groups of 9 can be made from these 45 students. To do this, we divide the total number of students by the group size: 45 ÷ 9 = 5 groups. Therefore, the number of groups that can be made is 5.\n",
            "The total number of students on the debate team is 5 boys + 40 girls = 45 students. If they are split into groups of 9, we need to divide 45 by 9. The calculation is 45 ÷ 9 = 5. Therefore, they can make 5 groups of 9.\n",
            "First, we need to calculate the total number of students in the debate team by adding the number of boys and girls: 5 boys + 40 girls = 45 students. Next, we divide the total number of students by the number of students in each group, which is 9, to find out how many groups can be made: 45 / 9 = 5 groups.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_entropy(predictions: list[Response]):\n",
        "    counter = Counter([prediction for prediction in predictions])\n",
        "\n",
        "    prob = [counter[i] / len(predictions) for i in counter]\n",
        "\n",
        "    numer = -sum([p * math.log(p) for p in prob])\n",
        "    denom = math.log(len(predictions))\n",
        "\n",
        "    return numer / denom"
      ],
      "metadata": {
        "id": "NTvpNG0GxcLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_to_responses = {\n",
        "    re.answer: re.chain_of_thought  # Store the entire Response object\n",
        "    for re in rep\n",
        "}"
      ],
      "metadata": {
        "id": "uasbQ2up1aOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for query, responses in query_to_responses.items():\n",
        "  print(query)\n",
        "  print(responses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRW3NdUt1lTW",
        "outputId": "8008f24a-1c9f-4657-8b5b-52e029e3f391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find the total number of members in the debate team, we add the number of boys and girls together. There are 5 boys and 40 girls, so the total is: 5 + 40 = 45. Next, we need to determine how many groups of 9 can be made from these 45 members. We do this by dividing the total number of members by the size of each group: 45 ÷ 9 = 5. Therefore, the team can make 5 groups of 9 members each.\n",
            "chain_of_thought='To find the total number of members in the debate team, we add the number of boys and girls together. There are 5 boys and 40 girls, so the total is: 5 + 40 = 45. Next, we need to determine how many groups of 9 can be made from these 45 members. We do this by dividing the total number of members by the size of each group: 45 ÷ 9 = 5. Therefore, the team can make 5 groups of 9 members each.' answer='5'\n",
            "First, we need to determine the total number of students in the debate team. There are 5 boys and 40 girls, so we add them together: 5 + 40 = 45 students in total. Next, we want to find out how many groups of 9 can be made from these 45 students. To do this, we divide the total number of students by the group size: 45 ÷ 9 = 5 groups. Therefore, the number of groups that can be made is 5.\n",
            "chain_of_thought='First, we need to determine the total number of students in the debate team. There are 5 boys and 40 girls, so we add them together: 5 + 40 = 45 students in total. Next, we want to find out how many groups of 9 can be made from these 45 students. To do this, we divide the total number of students by the group size: 45 ÷ 9 = 5 groups. Therefore, the number of groups that can be made is 5.' answer='5'\n",
            "The total number of students on the debate team is 5 boys + 40 girls = 45 students. If they are split into groups of 9, we need to divide 45 by 9. The calculation is 45 ÷ 9 = 5. Therefore, they can make 5 groups of 9.\n",
            "chain_of_thought='The total number of students on the debate team is 5 boys + 40 girls = 45 students. If they are split into groups of 9, we need to divide 45 by 9. The calculation is 45 ÷ 9 = 5. Therefore, they can make 5 groups of 9.' answer='5 groups'\n",
            "First, we need to calculate the total number of students in the debate team by adding the number of boys and girls: 5 boys + 40 girls = 45 students. Next, we divide the total number of students by the number of students in each group, which is 9, to find out how many groups can be made: 45 / 9 = 5 groups.\n",
            "chain_of_thought='First, we need to calculate the total number of students in the debate team by adding the number of boys and girls: 5 boys + 40 girls = 45 students. Next, we divide the total number of students by the number of students in each group, which is 9, to find out how many groups can be made: 45 / 9 = 5 groups.' answer=5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_repetitiveness(repo):\n",
        "\n",
        "    embedding = openai.OpenAI(api_key='sk-U7ti37t3osaeWme7m88923xFY2UMGVQLkeydTAywi3xI7TOP',\n",
        "                                              base_url=\"https://api.chatanywhere.tech/v1\").embeddings.create(input=repo.chain_of_thought, model=\"text-embedding-3-small\"\n",
        "    )\n",
        "    embedding = [item.embedding for item in embedding.data]\n",
        "    ttl = 0\n",
        "    num_comparisons = 0\n",
        "    for idx in range(len(embedding)):\n",
        "        for idx2 in range(idx + 1, len(embedding)):\n",
        "            ttl += cosine_similarity(embedding[idx], embedding[idx2])\n",
        "            num_comparisons += 1\n",
        "    return 2*ttl/(num_comparisons)*(num_comparisons - 1) if num_comparisons > 0 else 0"
      ],
      "metadata": {
        "id": "L0M8LP0S4m7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_entropy(predictions):\n",
        "    counter = Counter([prediction.answer for prediction in predictions])\n",
        "\n",
        "    prob = [counter[i] / len(predictions) for i in counter]\n",
        "\n",
        "    numer = -sum([p * math.log(p) for p in prob])\n",
        "    denom = math.log(len(predictions))\n",
        "\n",
        "    return numer / denom"
      ],
      "metadata": {
        "id": "JxtFZqO8-t0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score2 = score_entropy(rep)\n"
      ],
      "metadata": {
        "id": "4kLc8utl_bLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awCfJ1Hd_cYD",
        "outputId": "5d5bb5cd-65ad-4297-b1bc-287d119360ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4056390622295664"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for re in rep:\n",
        "  print(re.chain_of_thought)\n",
        "  print(re.answer)\n",
        "  score1 = score_repetitiveness(re)\n",
        "  print(score1 + score2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUC9Uc1S7rwH",
        "outputId": "534baffd-1b2a-4b03-cc42-9410e4519a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Janet’s ducks lay 16 eggs per day.', 'She eats 3 eggs for breakfast every morning, leaving her with 16 - 3 = 13 eggs.', 'She bakes 4 muffins with 4 eggs, leaving her with 13 - 4 = 9 eggs.', 'The remainder of the eggs that she sells is 9 eggs.', 'She sells each egg for $2, so her total earnings from selling the eggs is 9 * 2 = 18.']\n",
            "18\n",
            "10.673412190874297\n",
            "['Janet has 16 duck eggs.', 'She eats 3 eggs for breakfast, so remaining eggs after breakfast = 16 - 3 = 13 eggs.', 'She bakes muffins with 4 eggs, so remaining eggs after baking = 13 - 4 = 9 eggs.', \"Janet sells the remaining eggs (9) at the farmers' market for $2 each.\", 'Total earnings from selling eggs = 9 eggs * $2/egg = $18.']\n",
            "18\n",
            "10.010257086625494\n",
            "[\"Janet's ducks lay 16 eggs every day.\", 'She eats 3 eggs for breakfast, which means she has 16 - 3 = 13 eggs left.', 'She bakes muffins with 4 eggs, so now she has 13 - 4 = 9 eggs remaining.', \"Janet sells those 9 eggs at the farmers' market for $2 each, so she makes 9 * 2 = 18 dollars.\"]\n",
            "18\n",
            "5.9175779417026435\n",
            "[\"Janet's ducks lay a total of 16 eggs per day.\", 'She eats 3 eggs for breakfast and bakes with 4 eggs, totaling 3 + 4 = 7 eggs consumed by her.', 'To find out how many eggs she sells, subtract the eggs she consumed from the total: 16 - 7 = 9 eggs remain.', \"Janet sells these 9 eggs at the farmers' market for $2 each.\", 'To calculate her daily earnings: 9 eggs * $2/egg = $18.']\n",
            "18\n",
            "10.368847889223913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4pqn086L8OuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResponseScore(BaseModel):\n",
        "    query: str\n",
        "    response: Response\n",
        "    score: float\n",
        "\n",
        "    def format_response(self):\n",
        "        return dedent(\n",
        "            f\"\"\"\n",
        "            Q: {self.query}\n",
        "            A: {''.join(self.response)}. Therefore the answer is {self.response.answer}.\n",
        "            \"\"\"\n",
        "        )"
      ],
      "metadata": {
        "id": "B0FOlUNC6TMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = []\n",
        "for re in rep:\n",
        "  print(re.chain_of_thought)\n",
        "  print(re.answer)\n",
        "  query = query\n",
        "  score = query_to_entropy[re.answer] + 0.2 * score_repetitiveness(re.chain_of_thought)\n",
        "  print(score)\n",
        "  # a.append(ResponseScore(query='', response='t', score=score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOc_FA_W5dJG",
        "outputId": "70fd2ec0-7951-486f-ada9-6b56c4c1cb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find the total number of members in the debate team, we add the number of boys and girls together. There are 5 boys and 40 girls, so the total is: 5 + 40 = 45. Next, we need to determine how many groups of 9 can be made from these 45 members. We do this by dividing the total number of members by the size of each group: 45 ÷ 9 = 5. Therefore, the team can make 5 groups of 9 members each.\n",
            "5\n",
            "0.4967648485783058\n",
            "First, we need to determine the total number of students in the debate team. There are 5 boys and 40 girls, so we add them together: 5 + 40 = 45 students in total. Next, we want to find out how many groups of 9 can be made from these 45 students. To do this, we divide the total number of students by the group size: 45 ÷ 9 = 5 groups. Therefore, the number of groups that can be made is 5.\n",
            "5\n",
            "0.4967648485783058\n",
            "The total number of students on the debate team is 5 boys + 40 girls = 45 students. If they are split into groups of 9, we need to divide 45 by 9. The calculation is 45 ÷ 9 = 5. Therefore, they can make 5 groups of 9.\n",
            "5 groups\n",
            "0.5613033584309607\n",
            "First, we need to calculate the total number of students in the debate team by adding the number of boys and girls: 5 boys + 40 girls = 45 students. Next, we divide the total number of students by the number of students in each group, which is 9, to find out how many groups can be made: 45 / 9 = 5 groups.\n",
            "5\n",
            "0.5247899061489015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_responses(\n",
        "    predictions, trade_off_param: float\n",
        ") -> list[ResponseScore]:\n",
        "    query_to_responses: dict[str, list[Response]] = defaultdict(list)\n",
        "    for prediction, query in predictions:\n",
        "        query_to_responses[query].append(prediction)\n",
        "\n",
        "    # Change here: Use the actual response objects for each query\n",
        "    # instead of the original 'predictions' list\n",
        "    print(query_to_responses)\n",
        "    query_to_entropy = {\n",
        "        query: responses\n",
        "        for query, responses in query_to_responses.items()\n",
        "    }\n",
        "    print(query_to_entropy)\n",
        "    query_to_entropy = {\n",
        "        query: score_entropy(responses)\n",
        "        for query, responses in query_to_responses.items()\n",
        "    }\n",
        "\n",
        "    return [\n",
        "        ResponseScore(\n",
        "            query=query,\n",
        "            response=prediction,\n",
        "            score=query_to_entropy[query]\n",
        "            + trade_off_param * score_repetitiveness(prediction),\n",
        "        )\n",
        "        for prediction, query in predictions\n",
        "    ]"
      ],
      "metadata": {
        "id": "Rjo2LD0duK0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scored_responses = score_responses(rep, 0.2)\n",
        "\n",
        "chosen_examples = get_top_k_examples(scored_responses, k)\n",
        "\n",
        "# Step 2 : Run Self-Consistency\n",
        "final_responses = asyncio.run(generate_final_answers(query, chosen_examples, n))\n",
        "\n",
        "c = Counter([response.answer for response in final_responses])\n",
        "answer = c.most_common(1)[0][0]\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "OTCyGQy1su4s",
        "outputId": "76821271-9ca8-4f07-94cf-82594870e3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'list'>, {('answer', '5'): [('chain_of_thought', 'To find the total number of members in the debate team, we add the number of boys and girls together. There are 5 boys and 40 girls, so the total is: 5 + 40 = 45. Next, we need to determine how many groups of 9 can be made from these 45 members. We do this by dividing the total number of members by the size of each group: 45 ÷ 9 = 5. Therefore, the team can make 5 groups of 9 members each.'), ('chain_of_thought', 'First, we need to determine the total number of students in the debate team. There are 5 boys and 40 girls, so we add them together: 5 + 40 = 45 students in total. Next, we want to find out how many groups of 9 can be made from these 45 students. To do this, we divide the total number of students by the group size: 45 ÷ 9 = 5 groups. Therefore, the number of groups that can be made is 5.')], ('answer', '5 groups'): [('chain_of_thought', 'The total number of students on the debate team is 5 boys + 40 girls = 45 students. If they are split into groups of 9, we need to divide 45 by 9. The calculation is 45 ÷ 9 = 5. Therefore, they can make 5 groups of 9.')], ('answer', 5): [('chain_of_thought', 'First, we need to calculate the total number of students in the debate team by adding the number of boys and girls: 5 boys + 40 girls = 45 students. Next, we divide the total number of students by the number of students in each group, which is 9, to find out how many groups can be made: 45 / 9 = 5 groups.')]})\n",
            "{('answer', '5'): [('chain_of_thought', 'To find the total number of members in the debate team, we add the number of boys and girls together. There are 5 boys and 40 girls, so the total is: 5 + 40 = 45. Next, we need to determine how many groups of 9 can be made from these 45 members. We do this by dividing the total number of members by the size of each group: 45 ÷ 9 = 5. Therefore, the team can make 5 groups of 9 members each.'), ('chain_of_thought', 'First, we need to determine the total number of students in the debate team. There are 5 boys and 40 girls, so we add them together: 5 + 40 = 45 students in total. Next, we want to find out how many groups of 9 can be made from these 45 students. To do this, we divide the total number of students by the group size: 45 ÷ 9 = 5 groups. Therefore, the number of groups that can be made is 5.')], ('answer', '5 groups'): [('chain_of_thought', 'The total number of students on the debate team is 5 boys + 40 girls = 45 students. If they are split into groups of 9, we need to divide 45 by 9. The calculation is 45 ÷ 9 = 5. Therefore, they can make 5 groups of 9.')], ('answer', 5): [('chain_of_thought', 'First, we need to calculate the total number of students in the debate team by adding the number of boys and girls: 5 boys + 40 girls = 45 students. Next, we divide the total number of students by the number of students in each group, which is 9, to find out how many groups can be made: 45 / 9 = 5 groups.')]}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'answer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-88872c632103>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscored_responses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_responses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchosen_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_k_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscored_responses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 2 : Run Self-Consistency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-7e2586644e64>\u001b[0m in \u001b[0;36mscore_responses\u001b[0;34m(predictions, trade_off_param)\u001b[0m\n\u001b[1;32m     14\u001b[0m     }\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_to_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     query_to_entropy = {\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscore_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponses\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery_to_responses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-7e2586644e64>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_to_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     query_to_entropy = {\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscore_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponses\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery_to_responses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     }\n",
            "\u001b[0;32m<ipython-input-50-ff9a59473b23>\u001b[0m in \u001b[0;36mscore_entropy\u001b[0;34m(predictions)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-ff9a59473b23>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'answer'"
          ]
        }
      ]
    }
  ]
}